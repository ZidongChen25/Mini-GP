{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.special' has no attribute 'beta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m101\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     16\u001b[0m mywrap\u001b[38;5;241m=\u001b[39m trans\u001b[38;5;241m.\u001b[39mBetaCDF_Warp_Layer(\u001b[38;5;241m1\u001b[39m, c1, c0)\n\u001b[0;32m---> 17\u001b[0m k_icdfs\u001b[38;5;241m=\u001b[39m\u001b[43mmywrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m101\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m k_cdfs\u001b[38;5;241m=\u001b[39mmywrap\u001b[38;5;241m.\u001b[39minverse(k_icdfs)\n\u001b[1;32m     20\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[0;32m~/Dropbox/Research/Github/miniGP/gp_transform.py:51\u001b[0m, in \u001b[0;36mBetaCDF_Warp_Layer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# use the beta cdf to warp the input x\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# return torch.distributions.beta.Beta(self.a, self.b).cdf(x)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# OR explicitly compute the cdf\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# return x.pow(self.a.abs() - 1) * (1 - x).pow(self.b - 1) / torch.special.beta(self.a, self.b)\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma\u001b[38;5;241m.\u001b[39mabs() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.\u001b[39m) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m x)\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb\u001b[38;5;241m.\u001b[39mabs() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspecial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma\u001b[38;5;241m.\u001b[39mabs(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb\u001b[38;5;241m.\u001b[39mabs())\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.special' has no attribute 'beta'"
     ]
    }
   ],
   "source": [
    "# test the warp function\n",
    "# does not work yet 2023-12-20\n",
    "import torch\n",
    "import gp_transform as trans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "    \n",
    "\n",
    "fontdict = {\"fontsize\": 15}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.double\n",
    "torch.manual_seed(1)\n",
    "c1 = torch.rand(6, dtype=dtype, device=device) * 3 + 0.1\n",
    "c0 = torch.rand(6, dtype=dtype, device=device) * 3 + 0.1\n",
    "x = torch.linspace(0, 1, 101, dtype=dtype, device=device)\n",
    "\n",
    "mywrap= trans.BetaCDF_Warp_Layer(1, c1, c0)\n",
    "k_icdfs=mywrap.forward(x.unsqueeze(1).expand(101, 6))\n",
    "\n",
    "k_cdfs=mywrap.inverse(k_icdfs)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "for i in range(6):\n",
    "    ax.plot(x.cpu(), k_icdfs[:, i].cpu())\n",
    "ax.set_xlabel(\"Raw Value\", **fontdict)\n",
    "ax.set_ylabel(\"Transformed Value\", **fontdict)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
